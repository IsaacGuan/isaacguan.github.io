<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Isaac&#39;s Blog</title>
  
  <subtitle>Ayant le soleil en face, il faut que nous vivons fièrement</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://isaacguan.github.io/"/>
  <updated>2018-03-23T00:44:28.114Z</updated>
  <id>https://isaacguan.github.io/</id>
  
  <author>
    <name>Isaac Guan</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Tutte Embedding for Parameterization</title>
    <link href="https://isaacguan.github.io/2018/03/19/Tutte-Embedding-for-Parameterization/"/>
    <id>https://isaacguan.github.io/2018/03/19/Tutte-Embedding-for-Parameterization/</id>
    <published>2018-03-19T21:36:33.000Z</published>
    <updated>2018-03-23T00:44:28.114Z</updated>
    
    <content type="html"><![CDATA[<p>In terms of geometry processing, <a href="https://en.wikipedia.org/wiki/Tutte_embedding" target="_blank" rel="external">Tutte embedding</a>, also known as barycentric embedding, can be used for <a href="https://en.wikipedia.org/wiki/Mesh_parameterization" target="_blank" rel="external">mesh parameterization</a> by fixing the boundary vertices of the mesh on a certain convex polygon, and building a <a href="https://en.wikipedia.org/wiki/Tutte_embedding" target="_blank" rel="external">crossing-free straight-line embedding</a> with the interior vertices inside the convex boundary.</p><h1 id="Implementation-of-Tutte-Embedding"><a href="#Implementation-of-Tutte-Embedding" class="headerlink" title="Implementation of Tutte Embedding"></a>Implementation of Tutte Embedding</h1><p>In order to implement a Tutte Embedding, we have to use two vectors $u$ and $v$ to store the parameterized coordinates, and another two vectors $\bar u$ and $\bar v$ to store the boundary vertices. For the interior vertex $i$, we can directly applying the following equation on it to build the barycentric mapping, $j$ denotes the adjacent vertices of $i$.</p><p>$$\begin{equation}<br>\sum_{}a_{i,j}<br>\begin{pmatrix}<br>    u_i \\<br>    v_j<br>\end{pmatrix}<br>-a_{i,i}<br>\begin{pmatrix}<br>    u_i \\<br>    v_i<br>\end{pmatrix}<br>=0<br>\end{equation}$$</p><p>For those vertices on the boundary, we use the equation below and set $a_{i,i}=1$, to have them fixed on a convex shape:</p><p>$$\begin{equation}<br>\sum_{}a_{i,i}<br>\begin{pmatrix}<br>    u_i \\<br>    v_i<br>\end{pmatrix}<br>=<br>\begin{pmatrix}<br>    \bar u_i \\<br>    \bar v_i<br>\end{pmatrix}<br>\end{equation}$$</p><p>Thus, we can build the two linear systems in below, where $A=\{a_{i,j}\}$ is a sparse matrix storing all the weights $a_{i,j}$, and find the parameterized coordinates by solving for them.</p><p>$$\begin{equation}<br>\begin{cases}<br>Au=\bar u \\<br>Av=\bar v<br>\end{cases}<br>\end{equation}$$</p><p>I chose a disk as the convex shape for fixing the boundary vertices. And I am still using <a href="https://github.com/GeometryCollective/geometry-processing-js" target="_blank" rel="external">geometry-processing-js</a> as mesh library, which is the same library I used in <a href="https://isaacguan.github.io/2018/01/26/Mesh-Smoothing/">Mesh Smoothing</a>.</p><h1 id="Weighting-Schemes"><a href="#Weighting-Schemes" class="headerlink" title="Weighting Schemes"></a>Weighting Schemes</h1><p>I tried three different weight sets, namely uniform Laplacian weights, Laplace-Beltrami weights, and mean value weights.</p><h2 id="Uniform-Laplacian-Weights"><a href="#Uniform-Laplacian-Weights" class="headerlink" title="Uniform Laplacian Weights"></a>Uniform Laplacian Weights</h2><p>The uniform Laplacian weight set is easiest to build, but it does not take the geometric feature of the mesh into consideration. We can simply set the entries of the weight matrix in the following manner:</p><p>$$\begin{equation}<br>\begin{cases}<br>a_{i,j}=1 \\<br>a_{i,i}=-\sum_{}a_{i,j}=-degree_i<br>\end{cases}<br>\end{equation}$$</p><h2 id="Laplace-Beltrami-Weights"><a href="#Laplace-Beltrami-Weights" class="headerlink" title="Laplace-Beltrami Weights"></a>Laplace-Beltrami Weights</h2><p>We can also derive weights from the Laplace-Beltrami operator:</p><p>$$\begin{equation}<br>\begin{cases}<br>a_{i,j}=\frac{1}{2A_i}(\cot\alpha_{i,j}+\cot\beta_{i,j}) \\<br>a_{i,i}=-\sum_{}a_{i,j}<br>\end{cases}<br>\end{equation}$$</p><p>In the equations above, $A_i$ denotes the area of the Voronoi region of the vertex $i$, $\alpha_{i,j}$ and $\beta_{i,j}$ denote respectively the two corners opposite to the edge $(i,j)$, as is shown in <strong>Figure 1</strong>.</p><p><img src="/img/tutte_embedding_for_parameterization_1.jpg" alt="Tutte Embedding for Parameterization figure 1"></p><center><b>Figure 1:</b> Voronoi region of one vertex.</center><p>For calculating the value of $A_i$, we can use this formula, where $\Arrowvert x_i-x_j \Arrowvert$ is the length of edge $(i,j)$.</p><p>$$\begin{equation}<br>A_i=\frac{1}{8}\sum_{}(\cot\alpha_{i,j}+\cot\beta_{i,j})\Arrowvert x_i-x_j \Arrowvert^2<br>\end{equation}$$</p><p>As far as one triangle from the one-ring of a vertex is concerned, which is shown in <strong>Figure 2</strong>, the Voronoi region inside that triangle can be calculated as:</p><p>$$\begin{equation}<br>W=\frac{1}{8}\sum_{}(\Arrowvert x_i-x_j \Arrowvert^2\cot\alpha+\Arrowvert x_i-x_j \Arrowvert^2\cot\beta)<br>\end{equation}$$</p><p><img src="/img/tutte_embedding_for_parameterization_2.jpg" alt="Tutte Embedding for Parameterization figure 2"></p><center><b>Figure 2:</b> Voronoi region of one triangle of one-ring.</center><p>As the data structure of mesh is based on half edge, we can simply find the neighbor of a certain half edge by retrieving its previous half edge, e.g., in <strong>Figure 2</strong>, half edge $(j_2,i)$ is previous to half edge $(i,j_1)$. Thus, by traversing outgoing half edges associated on a vertex, we can easily calculate the Voronoi region of it using the following code snippet:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">let</span> area = <span class="number">0.0</span>;</div><div class="line"><span class="keyword">for</span> (<span class="keyword">let</span> h <span class="keyword">of</span> v.adjacentHalfedges()) &#123;</div><div class="line">    <span class="keyword">let</span> u2 = <span class="keyword">this</span>.vector(h.prev).norm2();</div><div class="line">    <span class="keyword">let</span> v2 = <span class="keyword">this</span>.vector(h).norm2();</div><div class="line">    <span class="keyword">let</span> cotAlpha = <span class="keyword">this</span>.cotan(h.prev);</div><div class="line">    <span class="keyword">let</span> cotBeta = <span class="keyword">this</span>.cotan(h);</div><div class="line">    area += (u2 * cotAlpha + v2 * cotBeta) / <span class="number">8</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h2 id="Mean-Value-Weights"><a href="#Mean-Value-Weights" class="headerlink" title="Mean Value Weights"></a>Mean Value Weights</h2><p>The Laplace-Beltrami weight takes the geometry of a mesh into account, but it could be negative with obtuse triangles. Based on the mean value theorem, we can the mean value weights, which are always positive and generate one-to-one mappings.</p><p>$$\begin{equation}<br>\begin{cases}<br>a_{i,j}=\frac{1}{\Arrowvert x_i-x_j \Arrowvert}(\tan(\frac{\delta_{i,j}}{2})+\tan(\frac{\gamma_{i,j}}{2})) \\<br>a_{i,i}=-\sum_{}a_{i,j}<br>\end{cases}<br>\end{equation}$$</p><p>In the equations above, $\Arrowvert x_i-x_j \Arrowvert$ is the length of edge $(i,j)$, $\delta_{i,j}$ and $\gamma_{i,j}$ are two neighboring corners on both sides of edge $(i,j)$, as is shown in <strong>Figure 3</strong>.</p><p><img src="/img/tutte_embedding_for_parameterization_3.jpg" alt="Tutte Embedding for Parameterization figure 3"></p><center><b>Figure 3</b></center><p>In the real implementation, like what we did in calculating the Voronoi region, we can still take advantage of the sequence of half edges to find the corresponding corners:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">let</span> delta = h.next.corner;</div><div class="line"><span class="keyword">let</span> gamma = h.twin.prev.corner;</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;In terms of geometry processing, &lt;a href=&quot;https://en.wikipedia.org/wiki/Tutte_embedding&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Tutte embedding&lt;/
      
    
    </summary>
    
    
      <category term="geometry processing" scheme="https://isaacguan.github.io/tags/geometry-processing/"/>
    
      <category term="parameterization" scheme="https://isaacguan.github.io/tags/parameterization/"/>
    
      <category term="tutte embedding" scheme="https://isaacguan.github.io/tags/tutte-embedding/"/>
    
  </entry>
  
  <entry>
    <title>Hough Transform for Plane Detection</title>
    <link href="https://isaacguan.github.io/2018/02/28/Hough-Transform-for-Plane-Detection/"/>
    <id>https://isaacguan.github.io/2018/02/28/Hough-Transform-for-Plane-Detection/</id>
    <published>2018-03-01T02:02:15.000Z</published>
    <updated>2018-03-19T21:37:12.487Z</updated>
    
    <content type="html"><![CDATA[<p>The <a href="https://en.wikipedia.org/wiki/Hough_transform" target="_blank" rel="external">Hough Transform</a> is a method for detecting parameterized objects, typically used for lines and circles in 2D space. Nowadays, with proliferation of acquisitive devices, deriving a massive point cloud is an easy task. As we can also parameterize objects in 3D, Hough Transform can be applied to detect planes in 3D point clouds as well.</p><h1 id="Parameterization-of-a-Plane"><a href="#Parameterization-of-a-Plane" class="headerlink" title="Parameterization of a Plane"></a>Parameterization of a Plane</h1><p>Similar to a line in 2D space, a plane in 3D can be described using a <a href="https://en.wikipedia.org/wiki/Linear_equation#Slope%E2%80%93intercept_form" target="_blank" rel="external">slope–intercept equation</a>, where $k_x$ is the slope in x-direction, $k_y$ is the slope in y-direction and $b$ is the intercept on z-axis:</p><p>$$\begin{equation}<br>z=k_xx+k_yy+b<br>\end{equation}$$</p><p>With this equation we can simply parameterize a plane as $(k_x,k_y,b)$.</p><p>However, values of $k_x$, $k_y$, and $b$ are unbounded, which would pose a problem when we try to parameterize a vertical plane. Thus, for computational reasons, we can write the plane equation in the <a href="https://en.wikipedia.org/wiki/Hesse_normal_form" target="_blank" rel="external">Hesse normal form</a>, where $\theta$ is the angle between the normal vector of this plane and the x-axis, $\phi$ is the angle between the normal vector and z-axis and $\rho$ is the distance from the plane to the origin:</p><p>$$\begin{equation}<br>x\cos\theta\sin\phi+y\sin\phi\sin\theta+z\cos\phi=\rho<br>\end{equation}$$</p><p>As is shown in <strong>Figure 1</strong>. The plane can be parameterized as $(\theta,\phi,\rho)$.</p><p><img src="/img/hough_transform_for_plane_detection_1.jpg" alt="Hough Transform for Plane Detection figure 1"></p><center><b>Figure 1:</b> Parameterization of a plane.</center><p>To find planes in a 3D point cloud, we have to calculate the Hough Transform for each point, which is to say that we parameterize every possible plane that go through every point in the $(\theta,\phi,\rho)$ Hough Space. For instance, <strong>Figure 2</strong> shows the parameterization of three points $(0,0,1)$, $(0,1,0)$ and $(1,0,0)$. Each point is marked as a 3D sinusoid curve in Hough Space and the intersection which is marked in black denotes the plane defined by the three points.</p><p><img src="/img/hough_transform_for_plane_detection_2.jpg" alt="Hough Transform for Plane Detection figure 2"></p><center><b>Figure 2:</b> Transformation of three points from original space to Hough Space.</center><h1 id="Hough-Methods"><a href="#Hough-Methods" class="headerlink" title="Hough Methods"></a>Hough Methods</h1><p>Basically, the algorithm for doing Hough Transform can be described as a voting method, where we discretize the Hough Space with a bunch of $(\theta,\phi,\rho)$ cells. A data structure called accumulator then is needed to store all these cells with a score parameter for every cell. Incrementing a cell means increasing the score of it by +1. Each point votes for all cells of $(\theta,\phi,\rho)$ that define a plane on which it may lie.</p><h2 id="Standard-Hough-Transform"><a href="#Standard-Hough-Transform" class="headerlink" title="Standard Hough Transform"></a>Standard Hough Transform</h2><p>A most basic and naïve Hough Transform algorithm for plane detection is outlined as follows:</p><p><strong><em>Begin</em></strong></p><p><em>Step 1:</em> Traverse all the points in the point cloud $P$;</p><p><em>Step 2:</em> For each point $p_i$ in $P$, vote for all the $A(\theta,\phi,\rho)$ cells in the accumulator $A$ defined by this point;</p><p><em>Step 3:</em> After the whole iteration, search for the most prominent cells in the accumulator $A$, that define the detected planes in $P$.</p><p><strong><em>End</em></strong></p><p>The Standard Hough Transform is performed in two stages: incrementing the cells, which needs $O(\lvert P \rvert \cdot N_\phi \cdot N_\theta)$ operations, and searching for the most prominent cells, which takes $O(N_\rho \cdot N_\phi \cdot N_\theta)$ time, where $\lvert P \rvert$ is the size of the point cloud, $N_\phi$ is the number of cells in direction of $\phi$, $N_\theta$ in direction of $\theta$ and $N_\rho$ in direction of $\rho$.</p><h2 id="Probabilistic-Hough-Transform"><a href="#Probabilistic-Hough-Transform" class="headerlink" title="Probabilistic Hough Transform"></a>Probabilistic Hough Transform</h2><p>In the Standard Hough Transform, the size of the point cloud $\lvert P \rvert$ is usually much larger than the number $N_\rho \cdot N_\phi \cdot N_\theta$ of cells in the accumulator array. We can simply reduce the number of points to improve the computational expenses. Thus, the Standard Hough Transform can be adapted to the Probabilistic Hough Transform, which is shown as follows:</p><p><strong><em>Begin</em></strong></p><p><em>Step 1:</em> Determine the size value $m$ and the threshold value $t$;</p><p><em>Step 2:</em> randomly select $m$ points to create $P^m \subset P$;</p><p><em>Step 3:</em> Do the Standard Hough Transform on the point set $P^m$;</p><p><em>Step 4:</em> Delete the cells from the accumulator $A$ with a value that does not reach $t$, and search for the most prominent cells in $A$, that define the detected planes in $P$.</p><p><strong><em>End</em></strong></p><p>The $m$ points $(m&lt;\lvert P \rvert)$ are randomly selected from the point cloud $P$, so the dominant part of the runtime is proportional to $O(m \cdot N_\phi \cdot N_\theta)$. However, the optimal choice of $m$ and the threshold $t$ depends on the actual problem, e.g., the number of planes, or the noise in the point cloud.</p><h3 id="Adaptive-Probabilistic-Hough-Transform"><a href="#Adaptive-Probabilistic-Hough-Transform" class="headerlink" title="Adaptive Probabilistic Hough Transform"></a>Adaptive Probabilistic Hough Transform</h3><p>In order to find the optimal subsample of the point cloud, we can use an adaptive method to determine the reasonable number of selected points. The Adaptive Probabilistic Hough Transform monitors the accumulator. The structure of the accumulator changes dynamically during the voting phase. As soon as stable structures emerge and turn into significant peaks, voting is terminated.</p><p><strong><em>Begin</em></strong></p><p><em>Step 1:</em> Check the stability order $m_k$ of the list of $k$ peaks $S_k$ in the accumulator, if it reaches the threshold value $t_k$ then finish;</p><p><em>Step 2:</em> Randomly select a small subset $P^m \subset P$;</p><p><em>Step 3:</em> Do the Standard Hough Transform on the point set $P^m$;</p><p><em>Step 4:</em> Merge the active list of peaks $S_k$ with the previous one, determine the stability order $m_k$, goto <em>Step 1</em>;</p><p><strong><em>End</em></strong></p><p>In this algorithm, The stability is described by a set $S_k$ of $k$ peaks in the list, if the set contains all largest peaks before and after one update phase. The number $m_k$ of consecutive lists in which $S_k$ is stable is called the stability order of $S_k$.</p><h3 id="Progressive-Probabilistic-Hough-Transform"><a href="#Progressive-Probabilistic-Hough-Transform" class="headerlink" title="Progressive Probabilistic Hough Transform"></a>Progressive Probabilistic Hough Transform</h3><p>The Progressive Probabilistic Hough Transform calculates stopping time for random selection of points. The algorithm stops whenever a cell count exceeds a threshold.</p><p><strong><em>Begin</em></strong></p><p><em>Step 1:</em> Check the input point cloud $P$, if it is empty then finish;</p><p><em>Step 2:</em> Update the accumulator with a single point $p_i$ randomly selected from $P$;</p><p><em>Step 3:</em> Remove $p_i$ from $P$ and add it to $P_{voted}$;</p><p><em>Step 4:</em> Check if the highest peak in the accumulator that was modified by the new point is higher than threshold $t$, if not then goto <em>Step 1</em>;</p><p><em>Step 5:</em> Select all points from $P$ and $P_{voted}$ that are close to the plane defined by the highest peak and add them to $P_{plane}$;</p><p><em>Step 6:</em> Search for the largest connected region $P_{region}$ in $P_{plane}$ and remove from $P$ all points in $P_{region}$;</p><p><em>Step 7:</em> Reset the accumulator by unvoting all the points in $P_{region}$;</p><p><em>Step 8:</em> If the area covered by $P_{region}$ is larger than a threshold, add it to the output list, goto <em>Step 1</em>;</p><p><strong><em>End</em></strong></p><p>In this algorithm, $P_{voted}$ is the point set of all the voted points before a plane is detected, $P_{plane}$ is the set of points in the detected planes, and $P_{region}$ denotes the largest connected region in $P_{plane}$. For determining the stopping time, threshold $t$ is predicted on the percentage of votes for one cell from all points that have voted.</p><h2 id="Randomized-Hough-Transform"><a href="#Randomized-Hough-Transform" class="headerlink" title="Randomized Hough Transform"></a>Randomized Hough Transform</h2><p>As we know the fact that a plane is defined by three points. For detecting planes, three points from the input space are mapped onto one point in the Hough Space. When a plane is represented by a large number of points, it is more likely that three points from this plane are randomly selected. Eventually the cells corresponding to actual planes receive more votes and are distinguishable from the other cells. Inspired by this idea, we can come up with an algorithm described as follows:</p><p><strong><em>Begin</em></strong></p><p><em>Step 1:</em> Check the input point cloud $P$, if it is empty then finish;</p><p><em>Step 2:</em> Randomly pick three points $p_1$, $p_2$ and $p_3$ from $P$;</p><p><em>Step 3:</em> If $p_1$, $p_2$ and $p_3$ fulfill the distance criterion, calculate plane $(\theta,\phi,\rho)$ spanned by $p_1$, $p_2$ and $p_3$ and increment cell $A(\theta,\phi,\rho)$ in the accumulator space;</p><p><em>Step 4:</em> If the count of $\lvert A(\theta,\phi,\rho) \rvert$ reaches threshold $t$, $(\theta,\phi,\rho)$ parameterize the detected plane, delete all points close to $(\theta,\phi,\rho)$ from $P$, and reset the accumulator $A$;</p><p><em>Step 5:</em> Goto <em>Step 1</em>;</p><p><strong><em>End</em></strong></p><p>This algorithm simply decreases the number of cells touched by exploiting the fact that a curve with $n$ parameters is defined by $n$ points. And also note that, if points are very far apart, they most likely do not belong to one plane. To take care of this and to diminish errors from sensor noise a distance criterion is introduced: $dist(p_1,p_2,p_3)≤dist_{max}$, i.e., the maximum point-to-point distance between $p_1$, $p_2$ and $p_3$ is below a fixed threshold.</p><h1 id="Accumulator"><a href="#Accumulator" class="headerlink" title="Accumulator"></a>Accumulator</h1><p>An inappropriate accumulator may lead to detection failures of some specific planes and difficulties in finding local maxima, displays low accuracy, large storage space, and low speed. A tradeoff has to be found between a coarse discretization that accurately detects planes and a small number of cells in the accumulator to decrease the time needed for the Hough Transform.</p><h2 id="Accumulator-Array"><a href="#Accumulator-Array" class="headerlink" title="Accumulator Array"></a>Accumulator Array</h2><p>For the standard implementation of the 2D Hough Transform, the Hough Space is divided into $N_\rho \times N_\theta$ rectangular cells. The size of the cells is variable and is chosen problem dependent. Using the same subdivision for the 3D Hough Space by dividing it into cuboid cells results in the patches seen in <strong>Figure 3</strong>. The cells closer to the poles are smaller and comprise less normal vectors. This means voting favors the larger equatorial cells.</p><p><img src="/img/hough_transform_for_plane_detection_3.jpg" alt="Hough Transform for Plane Detection figure 3"></p><center><b>Figure 3:</b> Accumulator array.</center><h2 id="Accumulator-Cube"><a href="#Accumulator-Cube" class="headerlink" title="Accumulator Cube"></a>Accumulator Cube</h2><p>We can also project the unit sphere $S^2$ onto the smallest cube that contains the sphere using the diffeomorphism:</p><p>$$\begin{equation}<br>\phi: S^2 \rightarrow cube, s \mapsto \Arrowvert s \Arrowvert_\infty<br>\end{equation}$$</p><p>Each face of the cube is divided into a regular grid, which is shown in <strong>Figure 4</strong>. With this design of accumulator, the difference of size between the patches on the unit sphere is negligible.</p><p><img src="/img/hough_transform_for_plane_detection_4.jpg" alt="Hough Transform for Plane Detection figure 4"></p><center><b>Figure 4:</b> Accumulator cube.</center><h2 id="Accumulator-Ball"><a href="#Accumulator-Ball" class="headerlink" title="Accumulator Ball"></a>Accumulator Ball</h2><p>The commonly used design, accumulator array, which is shown in <strong>Figure 3</strong>, causes the irregularity between the patches on the unit sphere. To solve this issue, we can simply customize the the resolution in terms of polar coordinates depending on the position of the sphere. The resolution of the longitude $\phi$ is kept as for the accumulator array, which is defined as $\phi^\prime$. In $\theta$ direction, the largest latitude circle is the equator located at $\phi=0$. For the unit sphere it has the $max_l = 2\pi$. The length of the latitude circle in the middle of the segment located above $\phi_i$ is given by $length_i=2\pi(\phi+\phi^\prime)$. The step width in $\theta$ direction for each slice is now computed as $\theta_{\phi_i}=\frac{360^\circ \cdot max_l}{length_i \cdot N_\theta}$, where $N_\theta$ is a constant that can be customized. The resulting design is illustrated in <strong>Figure 5</strong>.</p><p><img src="/img/hough_transform_for_plane_detection_5.jpg" alt="Hough Transform for Plane Detection figure 5"></p><center><b>Figure 5:</b> Accumulator ball.</center>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Hough_transform&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hough Transform&lt;/a&gt; is a method for detecting 
      
    
    </summary>
    
    
      <category term="geometry processing" scheme="https://isaacguan.github.io/tags/geometry-processing/"/>
    
      <category term="hough transform" scheme="https://isaacguan.github.io/tags/hough-transform/"/>
    
      <category term="parameterization" scheme="https://isaacguan.github.io/tags/parameterization/"/>
    
      <category term="plane detection" scheme="https://isaacguan.github.io/tags/plane-detection/"/>
    
  </entry>
  
  <entry>
    <title>Mesh Smoothing</title>
    <link href="https://isaacguan.github.io/2018/01/26/Mesh-Smoothing/"/>
    <id>https://isaacguan.github.io/2018/01/26/Mesh-Smoothing/</id>
    <published>2018-01-26T17:45:19.000Z</published>
    <updated>2018-02-06T18:00:24.237Z</updated>
    
    <content type="html"><![CDATA[<p>Mesh smoothing, also known as mesh denoising, is an important and widely discussed topic in terms of geometry processing. Basically, a mesh smoothing method takes three steps: loading a mesh from a file; smoothing that mesh; outputting the mesh to a file. Recently, I implemented a few basic algorithms regarding mesh smoothing.</p><h1 id="Selection-of-Mesh-Library"><a href="#Selection-of-Mesh-Library" class="headerlink" title="Selection of Mesh Library"></a>Selection of Mesh Library</h1><p>There are a lot of mesh libraries that give us a data structure so that we can use to build a mesh for an object file. What I am using is the <a href="https://github.com/GeometryCollective/geometry-processing-js" target="_blank" rel="external">geometry-processing-js</a> library. It is a library written in JavaScript which constructs a mesh based on half edge. It also gives plenty of predefined functions regarding the components of a mesh e.g. half edge, vertex, edge, face, etc. Besides, it also includes a linear algebra library which makes it handy for users to do matrix-vector operations.</p><h1 id="Mesh-Smoothing-Algorithms"><a href="#Mesh-Smoothing-Algorithms" class="headerlink" title="Mesh Smoothing Algorithms"></a>Mesh Smoothing Algorithms</h1><p>I implemented two algorithms for mesh smoothing, a mean filtering algorithm, and a weighted mean filtering algorithm.</p><h2 id="Mean-Filtering-Algorithm"><a href="#Mean-Filtering-Algorithm" class="headerlink" title="Mean Filtering Algorithm"></a>Mean Filtering Algorithm</h2><p>A most naïve mean filtering algorithm goes as follows:</p><p><strong><em>Begin</em></strong></p><p><em>Step 1:</em> Create a Hash Map $positions$ mapping each index of vertex with its position to be updated;</p><p><em>Step 2:</em> For each vertex $v$ in the mesh, calculate $positions[v]$ by the average position of the neighbor vertices in the one-ring of $v$;</p><p><em>Step 3:</em> After the whole iteration, update the positions of vertices in the mesh by the Hash Map $positions$.</p><p><strong><em>End</em></strong></p><p>However, if the object has some holes on it, this algorithm could cause the holes to enlarge after times of iteration, which is shown in <strong>Figure 1</strong>.</p><p><img src="/img/mesh_smoothing_1.jpg" alt="Mesh Smoothing figure 1"></p><center><b>Figure 1:</b> Holes enlarge on the object, steps = 5.</center><p>Sometimes, we don’t like such distortion, so it is necessary to preserve the boundary of holes on the mesh. We can add a step to the algorithm to constrain the vertices of boundary edges:</p><p><strong><em>Begin</em></strong></p><p><em>Step1:</em> Create a Hash Map $positions$ mapping each index of vertex with its position to be updated;</p><p><em>Step2:</em> For each vertex $v$ in the mesh, calculate $positions[v]$ by the average position of the neighbor vertices in the one-ring of $v$;</p><p><em>Step3:</em> To preserve the boundary of holes on the mesh, if vertex $v$ is on boundary, update $positions[v]$ to the original position of vertex $v$ in the mesh;</p><p><em>Step4:</em> After the whole iteration, update the positions of vertices in the mesh by the Hash Map $positions$.</p><p><strong><em>End</em></strong></p><h2 id="Weighted-Mean-Filtering-Algorithm"><a href="#Weighted-Mean-Filtering-Algorithm" class="headerlink" title="Weighted Mean Filtering Algorithm"></a>Weighted Mean Filtering Algorithm</h2><p>The weighting method simply weights each neighboring vertex by the area of the two faces incident to it. The weighted mean filtering algorithm goes like this:</p><p><strong><em>Begin</em></strong></p><p><em>Step1:</em>  Create a Hash Map $positions$ that maps each index of vertex to its position to be updated;</p><p><em>Step2:</em> For each vertex $v$ in the mesh, traverse its neighborhood vertices. And for each neighbor vertex $nv$ calculate the weight value on each neighborhood vertex $weightnv$ by adding area of the two incident faces together;</p><p><em>Step3:</em> After the traversal of neighborhood vertices, calculate the total weight $weight$ on the vertex $v$ by accumulating every $weightnv$, and calculate $positions[v]=\frac{\sum_{} weightnv \cdot position\,of\,nv}{weight}$;</p><p><em>Step4:</em> To preserve the boundary of holes on the mesh, if vertex $v$ is on boundary, update $positions[v]$ to the original position of vertex $v$ in the mesh;</p><p><em>Step5:</em> After the whole iteration, update the positions of vertices in the mesh by the Hash Map $positions$.</p><p><strong><em>End</em></strong></p><p>However, in the implementation, I found this could cause the faces of the mesh overlapping one another after several times of iterations, because the position of vertex could fall outside its one-ring neighborhood. As shown in <strong>Figure 2</strong>, overlapping occurs after 5 times of iteration.</p><p><img src="/img/mesh_smoothing_2.jpg" alt="Mesh Smoothing figure 2"></p><center><b>Figure 2:</b> Overlapping of faces, steps = 5.</center><p>In order to prevent such thing from happening, I tried to find those vertices which could fall outside its neighborhood during an iteration. The one-ring neighborhood of one vertex is actually a star-shaped polygon so that we can use the left-turn/right-turn check to decide whether the vertex is inside it or not.</p><p>To find out the star-shaped neighborhood of a certain vertex $v$, we should first project all the neighbors onto the plane which is defined by vertex $v$ and its normal vector $n$. We can find the projection $q=(x^\prime,y^\prime,z^\prime)$ of vertex $p=(x,y,z)$ on the plane that defined by the normal $n=(a,b,c)$ and vertex $v=(x_0,y_0,z_0)$ in the way below.</p><p>There are following implicit geometric relationships between $p$, $q$, $n$ and $v$: $pq \parallel n$ and $vq \perp n$.</p><p>The following equation can be derived from $pq \parallel n$:</p><p>$$\begin{equation}<br>\frac{x^\prime-x}{a}=\frac{y^\prime-y}{b}=\frac{z^\prime-z}{c}=t \tag{1} \label{eq:1}<br>\end{equation}$$</p><p>And from $vq \perp n$, we can derive:</p><p>$$\begin{equation}<br>a(x^\prime-x_0)+b(y^\prime-y_0)+c(z^\prime-z_0)=0 \tag{2} \label{eq:2}<br>\end{equation}$$</p><p>Combining $\eqref{eq:1}$ and $\eqref{eq:2}$, we can solve for $t$:</p><p>$$\begin{equation}<br>t=\frac{ax_0+by_0+cz_0-(ax+by+cz)}{a^2+b^2+c^2} \tag{3} \label{eq:3}<br>\end{equation}$$</p><p>Then we can solve for the projection $q=(x^\prime,y^\prime,z^\prime)$ by combining $\eqref{eq:1}$ and $\eqref{eq:3}$.</p><p>As the data structure of mesh is based on half edge, and all the faces are defined by half edges in counter-clock-wise order. Thus, for each vertex $v$, we can simply get the boundary edges of a star-shaped neighborhood in counter-clock-wise order, project them along with the position to be updated $positions[v]$ onto the plane that is defined by vertex $v$ and its normal vector $n$. Then we can do the left-turn/right-turn check on that plane to see whether the new position for vertex $v$ $positions[v]$ is outside its neighborhood polygon or not.</p><p>So the modified algorithm goes as follows:</p><p><strong><em>Begin</em></strong></p><p><em>Step1:</em> Create a Hash Map $positions$ that maps each index of vertex to its position to be updated;</p><p><em>Step2:</em> For each vertex $v$ in the mesh, traverse its neighborhood vertices. And for each neighbor vertex $nv$ calculate the weight value on each neighborhood vertex $weightnv$ by adding area of the two incident faces together;</p><p><em>Step3:</em> After the traversal of neighborhood vertices, calculate the total weight $weight$ on the vertex $v$ by accumulating every $weightnv$, and calculate $positions[v]=\frac{\sum_{} weightnv \cdot position\,of\,nv}{weight}$;</p><p><em>Step4:</em> Check whether $positions[v]$ falls outside its one-ring neighborhood, if so, use the mean filtering algorithm to update the new position;</p><p><em>Step5:</em> To preserve the boundary of holes on the mesh, if vertex $v$ is on boundary, update $positions[v]$ to the original position of vertex $v$ in the mesh;</p><p><em>Step6:</em> After the whole iteration, update the positions of vertices in the mesh by the Hash Map $positions$.</p><p><strong><em>End</em></strong></p><h1 id="Results-and-Conclusions"><a href="#Results-and-Conclusions" class="headerlink" title="Results and Conclusions"></a>Results and Conclusions</h1><p>As for the mean filtering algorithm, <strong>Figure 3</strong> shows the results for after applying it on different objects with different step numbers.</p><p><img src="/img/mesh_smoothing_3.jpg" alt="Mesh Smoothing figure 3"></p><center><b>Figure 3:</b> Results of mean filtering algorithm.</center><p>As for the weighted mean filtering algorithm, <strong>Figure 4</strong> shows the results for after applying it on different objects with different step numbers.</p><p><img src="/img/mesh_smoothing_4.jpg" alt="Mesh Smoothing figure 4"></p><center><b>Figure 4:</b> Results of weighted mean filtering algorithm.</center><p>We can conclude that the results of both algorithms basically look alike, and both of them could cause the volume of object to shrink if we apply too many times.</p><p>I have also uploaded the project to this blog: <a href="https://isaacguan.github.io/projects/mesh-smoothing">/projects/mesh-smoothing</a>, we can go there to see how exactly the algorithms work.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Mesh smoothing, also known as mesh denoising, is an important and widely discussed topic in terms of geometry processing. Basically, a me
      
    
    </summary>
    
    
      <category term="geometry processing" scheme="https://isaacguan.github.io/tags/geometry-processing/"/>
    
      <category term="mesh smoothing" scheme="https://isaacguan.github.io/tags/mesh-smoothing/"/>
    
  </entry>
  
  <entry>
    <title>Implementation of Voronoi Diagram and Delaunay Triangulation</title>
    <link href="https://isaacguan.github.io/2017/12/22/Implementation-of-Voronoi-Diagram-and-Delaunay-Triangulation/"/>
    <id>https://isaacguan.github.io/2017/12/22/Implementation-of-Voronoi-Diagram-and-Delaunay-Triangulation/</id>
    <published>2017-12-23T01:28:50.000Z</published>
    <updated>2017-12-24T02:39:15.479Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://en.wikipedia.org/wiki/Voronoi_diagram" target="_blank" rel="external">Voronoi diagram</a> and <a href="https://en.wikipedia.org/wiki/Delaunay_triangulation" target="_blank" rel="external">Delaunay triangulation</a> are dual representations of a set of points to each other. Due to their wide application in science and technology, Voronoi diagram and Delaunay triangulation play important roles in the field of Computational Geometry. In this post, I am going to introduce an implementation of an algorithm to derive both Voronoi Diagram and Delaunay Triangulation of a set of points in the plane.</p><h1 id="Voronoi-Diagram-and-Delaunay-Triangulation"><a href="#Voronoi-Diagram-and-Delaunay-Triangulation" class="headerlink" title="Voronoi Diagram and Delaunay Triangulation"></a>Voronoi Diagram and Delaunay Triangulation</h1><p>The Voronoi diagram of a set of points, also known as Thiessen polygons, is a partitioning of a plane into regions by a set of continuous polygons consisting of perpendicular bisectors of the connecting lines of two adjacent points. These regions are called Voronoi cells. And for each point in the set, there is a corresponding Voronoi cell consists of all points closer to that point than to any other.</p><p>The Delaunay triangulation of a set of points is dual to its Voronoi diagram. It is a collection of connected but non-overlapping triangles, and the outer circumcircle of these triangles does not contain any other points in this set.</p><h1 id="Design-of-the-Algorithm"><a href="#Design-of-the-Algorithm" class="headerlink" title="Design of the Algorithm"></a>Design of the Algorithm</h1><p>There are a lot of ways to generate a Voronoi diagram from a set of points in the plane. In this implementation, I obtained the Voronoi diagram from generating its dual, the Delaunay triangulation. Generally speaking, for the set of $n$ points $P=\{p_1, p_2, …, p_n\}$ in $\mathbb{R}^2$, the algorithm goes in this way: the Delaunay triangulation of the set of points is firstly generated, then we calculate the center of the circumcircle of each triangle and finally we connect these centers with straight lines and form the polygon mesh generated from the vertices of the triangles.</p><h2 id="Design-of-the-Data-Structure"><a href="#Design-of-the-Data-Structure" class="headerlink" title="Design of the Data Structure"></a>Design of the Data Structure</h2><p>I implemented this algorithm in object oriented language, so the design of data structure is in the form of class.</p><p>Point:</p><figure class="highlight cs"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> <span class="title">Point</span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">double</span> x, y, z;</div><div class="line">    <span class="keyword">public</span> List&lt;<span class="keyword">int</span>&gt; adjoinTriangles;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Point</span>(<span class="params"><span class="keyword">double</span> x, <span class="keyword">double</span> y, <span class="keyword">double</span> z</span>)</span></div><div class="line"><span class="function">    </span>&#123;</div><div class="line">        <span class="keyword">this</span>.x = x;</div><div class="line">        <span class="keyword">this</span>.y = y;</div><div class="line">        <span class="keyword">this</span>.z = z;</div><div class="line">        adjoinTriangles = <span class="keyword">new</span> List&lt;<span class="keyword">int</span>&gt;();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>Voronoi edge:</p><figure class="highlight cs"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> <span class="title">VoronoiEdge</span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">public</span> Point start, end;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">VoronoiEdge</span>(<span class="params">Point start, Point end</span>)</span></div><div class="line"><span class="function">    </span>&#123;</div><div class="line">        <span class="keyword">this</span>.start = start;</div><div class="line">        <span class="keyword">this</span>.end = end;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>Delaunay edge:</p><figure class="highlight cs"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> <span class="title">DelaunayEdge</span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">int</span> start, end;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DelaunayEdge</span>(<span class="params"><span class="keyword">int</span> start, <span class="keyword">int</span> end</span>)</span></div><div class="line"><span class="function">    </span>&#123;</div><div class="line">        <span class="keyword">this</span>.start = start;</div><div class="line">        <span class="keyword">this</span>.end = end;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>Triangle:</p><figure class="highlight cs"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> <span class="title">Triangle</span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">int</span> vertex1, vertex2, vertex3;</div><div class="line">    <span class="keyword">public</span> Point center;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">double</span> radius;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Triangle</span>(<span class="params"><span class="keyword">int</span> vertex1, <span class="keyword">int</span> vertex2, <span class="keyword">int</span> vertex3</span>)</span></div><div class="line"><span class="function">    </span>&#123;</div><div class="line">        <span class="keyword">this</span>.vertex1 = vertex1;</div><div class="line">        <span class="keyword">this</span>.vertex2 = vertex2;</div><div class="line">        <span class="keyword">this</span>.vertex3 = vertex3;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>On top of that, I defined a point list and a triangle list under the Collections class to store all the points in the point set $P$ and all the triangles during the procedure of triangulation as global variables:</p><figure class="highlight cs"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> <span class="title">Collections</span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> List&lt;Point&gt; allPoints;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> List&lt;Triangle&gt; allTriangles;</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>Thus, in the Point class, DelaunayEdge class and Triangle class, I can use an integer to represent the index of a certain point or triangle from the global lists, and retrieve it directly.</p><h2 id="Build-up-the-Vonoroi-Diagram"><a href="#Build-up-the-Vonoroi-Diagram" class="headerlink" title="Build up the Vonoroi Diagram"></a>Build up the Vonoroi Diagram</h2><p>The algorithm of building up a Vonoroi diagram goes in this way:</p><p><strong><em>Begin</em></strong></p><p><em>Step 1:</em> Obtain the Delaunay triangulation by generating the list of Delaunay edges.</p><p><em>Step 2:</em> Traverse all the Delaunay edges.</p><p><em>Step 3:</em> For each Delaunay edge, traverse the two triangle lists stored with the start point and the end point, and find the two same triangles in the two lists which are the adjacent triangles of this Delaunay edge.</p><p><em>Step 4:</em> Construct a Voronoi edge by connecting the two centers of the circumcles of the two adjacent triangles and add it to the Voronoi edge list.</p><p><strong><em>End</em></strong></p><h2 id="Conduct-the-Delaunay-Triangulation"><a href="#Conduct-the-Delaunay-Triangulation" class="headerlink" title="Conduct the Delaunay Triangulation"></a>Conduct the Delaunay Triangulation</h2><p>I planned to apply the <a href="https://en.wikipedia.org/wiki/Bowyer%E2%80%93Watson_algorithm" target="_blank" rel="external">Bowyer–Watson algorithm</a> for computing the Delaunay triangulation. A most naïve Bowyer–Watson algorithm goes like this:</p><p><strong><em>Begin</em></strong></p><p><em>Step 1:</em> Construct a ‘super’ triangle that covers all the points from the point set, add it to the Delaunay triangle list. </p><p><em>Step 2:</em> Insert points from the point set $P={p_1, p_2, …, p_n}$ to the ‘super’ triangle one by one.</p><p><em>Step 3:</em> For each point $p_i$ inserted, traverse the Delaunay triangle list to find all the triangles whose circumcircles cover this point $p_i$ as invalid triangles, delete these triangles from the Delaunay triangle list and delete all the common edges of these triangles, and leave a star-shaped polygonal hole.</p><p><em>Step 4:</em> Connect the point $p_i$ to all the vertices of this star-shaped polygon, and add the newly formed triangles to the Delaunay triangle list.</p><p><em>Step 5:</em> After all the points are inserted, obtain the Delaunay edge list from the Delaunay triangle list, and delete the edges from the Delaunay edge list that contain a vertex of the original ‘super’ triangle.</p><p><strong><em>End</em></strong></p><p>The following pictures can better illustrate the key steps of this algorithm. As shown in <strong>Figure 1</strong>, when a new point is inserted, all the triangles whose circumcircles contain this point will be found. The common edges of these triangles, which are highlighted in yellow, will be deleted, leaving the star-shaped boundary in red.</p><p><img src="/img/implementation_of_voronoi_diagram_and_delaunay_triangulation_1.jpg" alt="Implementation of Voronoi Diagram and Delaunay Triangulation figure 1"></p><center><b>Figure 1</b></center><p>And then, the inserted point will be connected to all the vertices of the star-shaped polygon, as shown in <strong>Figure 2</strong>, the new Delaunay triangles will be formed.</p><p><img src="/img/implementation_of_voronoi_diagram_and_delaunay_triangulation_2.jpg" alt="Implementation of Voronoi Diagram and Delaunay Triangulation figure 2"></p><center><b>Figure 2</b></center><p>However, the aforementioned naïve manner of Delaunay triangulation is clearly an $O(n^2)$ time algorithm that is incapable of handling a massive amount of points.</p><p>For improving its efficiency, we can first sort the set of points by x-coordinate, and use an open list and a closed list to store all the Delaunay triangles. In each time a point is inserted, all the triangles with circumcircles to the left of the inserting point are put into the closed list and removed from the open list. All the new triangles generated in an insertion are put into the open list. So in each time of insertion, we just have to traverse the open list to find the invalid triangles, the length of the sequential search of triangles is much reduced.</p><p>Besides, in order to derive the Voronoi diagram, when a new point is inserted, all the newly formed triangles that are incident on the point are put into the triangle list that is stored with the point.</p><p>Thus, the optimized algorithm goes as follows:</p><p><strong><em>Begin</em></strong></p><p><em>Step 1:</em> Sort the points in the point set $P={p_1, p_2, …, p_n}$ by x-coordinate.</p><p><em>Step 2:</em> Construct a ‘super’ triangle that covers all the points from the point set, add it to the open list. </p><p><em>Step 3:</em> Insert points from $P$ to the ‘super’ triangle one by one in ascending order of x-coordinates.</p><p><em>Step 4:</em> For each point $p_i$ inserted, traverse the open list to: 1) find all the triangles with circumcircles lying to the left of the point $p_i$, delete these triangles from the open list and add them to the closed list; 2) find all the triangles with circumcircles covering this point $p_i$ as invalid triangles, delete these triangles from the open list and the triangle list stored with $p_i$, delete all the common edges of these triangles, leaving a star-shaped polygonal hole.</p><p><em>Step 5:</em> Connect the point $p_i$ to all the vertices of this star-shaped polygon, and add the newly formed triangles to the open list and the triangle list stored with $p_i$.</p><p><em>Step 6:</em> After all the points are inserted, merge the open list and the closed list into the Delaunay triangle list, obtain the Delaunay edge list from the Delaunay triangle list, and delete the edges from the Delaunay edge list that contain a vertex of the original ‘super’ triangle.</p><p><strong><em>End</em></strong></p><h1 id="Time-Complexity-of-the-Algorithm"><a href="#Time-Complexity-of-the-Algorithm" class="headerlink" title="Time Complexity of the Algorithm"></a>Time Complexity of the Algorithm</h1><p>The optimized algorithm for Delaunay triangulation takes $O(nlogn)$ time. As Delaunay triangulation is a planar graph, the number of triangles incident on one point is constant, so the procedure of finding adjacent triangles takes constant time and the time of generating Voronoi diagram is $O(n)$. Therefore, the total running time of this algorithm is $O(nlogn)$.</p><h1 id="Implementation-of-the-Algorithm"><a href="#Implementation-of-the-Algorithm" class="headerlink" title="Implementation of the Algorithm"></a>Implementation of the Algorithm</h1><p>This algorithm is implemented in C#. <strong>Figure 3</strong> shows the result of the implementation of this algorithm, it is capable of handling massive input of 10000 points.</p><p><img src="/img/implementation_of_voronoi_diagram_and_delaunay_triangulation_3.jpg" alt="Implementation of Voronoi Diagram and Delaunay Triangulation figure 3"></p><center><b>Figure 3:</b> Voronoi diagram and Delaunay triangulation for 10000 points.</center><p>The GitHub repository of this implementation is <a href="https://github.com/IsaacGuan/Voronoi-Delaunay" target="_blank" rel="external">IsaacGuan/Voronoi-Delaunay</a>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Voronoi_diagram&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Voronoi diagram&lt;/a&gt; and &lt;a href=&quot;https://en.wikipe
      
    
    </summary>
    
    
      <category term="computational geometry" scheme="https://isaacguan.github.io/tags/computational-geometry/"/>
    
      <category term="voronoi diagram" scheme="https://isaacguan.github.io/tags/voronoi-diagram/"/>
    
      <category term="delaunay triangulation" scheme="https://isaacguan.github.io/tags/delaunay-triangulation/"/>
    
  </entry>
  
  <entry>
    <title>Width of a Set in the Plane</title>
    <link href="https://isaacguan.github.io/2017/11/19/Width-of-a-Set-in-the-Plane/"/>
    <id>https://isaacguan.github.io/2017/11/19/Width-of-a-Set-in-the-Plane/</id>
    <published>2017-11-19T15:19:12.000Z</published>
    <updated>2017-11-19T18:24:28.787Z</updated>
    
    <content type="html"><![CDATA[<p>The book <a href="http://reports-archive.adm.cs.cmu.edu/anon/anon/usr/ftp/scan/CMU-CS-80-101.pdf" target="_blank" rel="external"><em>Geometric Transforms for Fast Geometric Algorithms</em></a> introduces an interesting algorithm from page 84 of computing the diameter of a set of points in two dimensions. Inspired by this, I come up with a solution of computing the width of a set using geometric transformation.</p><h1 id="Definition-of-the-Width-of-a-Set"><a href="#Definition-of-the-Width-of-a-Set" class="headerlink" title="Definition of the Width of a Set"></a>Definition of the Width of a Set</h1><p>Let $S$ be a set of $n$ points in $\mathbb{R}^2$. If $l$ and $l^\prime$ are two parallel lines, then the region between them is called a slab. The width of $S$ is defined to be the minimum distance between the bounding lines of any slab that contains all points of $S$.</p><h1 id="Characterization-of-the-Width"><a href="#Characterization-of-the-Width" class="headerlink" title="Characterization of the Width"></a>Characterization of the Width</h1><p>Before presenting the width-finding algorithm, I^\primed like first to characterize the width of a set of points, introduce some terminology and prove several theorems.</p><p>When we say that $A$ is contained in $B$, it means that every point of $A$ also lies in $B$. The bounding lines of a slab could contain a vertex or an edge of the convex hull $CH(S)$ of the set of points $S$.</p><p><strong>Theorem 1:</strong> Let $l$ and $l^\prime$ be two parallel lines that define the width of $S$, both $l$ and $l^\prime$ contain a vertex of the convex hull $CH(S)$ of $S$.</p><p><strong>Proof.</strong> Assume otherwise. The width is determined by parallel lines $l$ and $l^\prime$, and $l$ contains a vertex of $CH(S)$, $l^\prime$ does not, as shown in <strong>Figure 1</strong>. Then there must exists a line $l^{\prime\prime}$ closer to the set of points $S$ and produces a smaller distance. Q.E.D.</p><p><img src="/img/width_of_a_set_in_the_plane_1.jpg" alt="width of a set in the plane figure 1"></p><center><b>Figure 1</b></center><p><strong>Theorem 2:</strong> Let $l$ and $l^\prime$ be two parallel lines that define the width of $S$, at least one of $l$ and $l^\prime$ contain an edge of the convex hull $CH(S)$ of $S$.</p><p><strong>Proof.</strong> Assume otherwise. The width is determined by parallel lines $l$ and $l^\prime$ which both pass a vertex but neither of them passes an edge. We can rotate the parallel lines in preferred direction of rotation which means we rotate $l$ and $l^\prime$ about the two vertices they pass to form new parallel lines $l_1$ and $l^\prime_1$ and the distance between $l_1$ and $l^\prime_1$ is smaller. This contradicts the assumption. Q.E.D.</p><h1 id="Computing-the-Width"><a href="#Computing-the-Width" class="headerlink" title="Computing the Width"></a>Computing the Width</h1><p>We can divide the convex hull into 2 parts: the upper hull and the lower hull, so that when one of the parallel lines of support of $S$ meets the convex hull on the upper hull, the other is on the lower hull.</p><p>According to the <a href="https://en.wikipedia.org/wiki/Linear_programming#Duality" target="_blank" rel="external">duality transformation</a>, a non-vertical line $y=kx+b$ can be transformed into the point $(k,b)$ which is formed by the slope and intercept of the line. And a point $(a,b)$ can be transformed into the line $y=k(x-a)+b$ which means the set of lines that pass through it.</p><p>Hence, we define the transform of an edge of the convex hull $CH(S)$ of $S$ as the slope of the line containing that edge and the transform of a vertex of $CH(S)$ as the set of slopes of lines that pass through it. I.e., the line containing an edge: $y=kx+b$ can be mapped to the one dimensional point $(k)$ and the vertex that lies between two edges: $y=k_1x+b_1$ and $y=k_2x+b_2$ can be mapped to the closed interval $[k_1,k_2]$. As shown in <strong>Figure 2</strong>, the convex hull is transformed into a line which consists of a upper part and a lower part.</p><p><img src="/img/width_of_a_set_in_the_plane_2.jpg" alt="width of a set in the plane figure 2"></p><center><b>Figure 2:</b> The transform.</center><p>As the slopes of the edges of the convex hull are already sorted, when we transform the convex hull to a line, the upper and lower sets of points and intervals on the line are in sorted order.</p><p>As is known from <strong>Theorem 1</strong>, the parallel lines of support pass through an edge and a vertex of the convex hull $CH(S)$, which means the corresponding point and interval pair contained in the parallel lines must intersect on the upper and lower lines, e.g., $P_5$ and $l_8$, $P_6$ and $l_2$ in <strong>Figure 2</strong>.</p><p>Thus, finding the width of a set of points $S$ can be reduced to scanning the intersections of point and interval pairs on the upper and lower hulls of its convex hull $CH(S)$.</p><p>To summarize, the width of a set of points $S$ can be computed in the following manner.</p><p><strong><em>Begin</em></strong></p><p><em>Step 1:</em> Construct the convex hull $CH(S)$ of $S$.</p><p><em>Step 2:</em> Apply the transform to obtain two ordered sets of points and intervals.</p><p><em>Step 3:</em> Scan the sets for intersections between the intervals of one set and the points of the other, generating the corresponding vertex and edge pair. For each such pair, compute the distance between the vertex and the extended edge, and note the smallest such distance. When the scan is complete, that distance is the width.</p><p><strong><em>End</em></strong></p><h1 id="Time-Complexity"><a href="#Time-Complexity" class="headerlink" title="Time Complexity"></a>Time Complexity</h1><p>According to the <a href="https://en.wikipedia.org/wiki/Gift_wrapping_algorithm" target="_blank" rel="external">gift wrapping algorithm</a> and the <a href="https://en.wikipedia.org/wiki/Graham_scan" target="_blank" rel="external">Graham scan algorithm</a>, the running time of finding the convex hull of a set of points can be minimized to $O(nlogh)$, where $h$ is the number of points on the convex hull. And obtaining the two ordered sets and scanning the sets both takes $O(h)$ time. Therefore, finding the width of a set of points $S$ in $\mathbb{R}^2$ takes $O(nlogh)$ time.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;The book &lt;a href=&quot;http://reports-archive.adm.cs.cmu.edu/anon/anon/usr/ftp/scan/CMU-CS-80-101.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;&lt;em&gt;Geom
      
    
    </summary>
    
    
      <category term="computational geometry" scheme="https://isaacguan.github.io/tags/computational-geometry/"/>
    
      <category term="convex hull" scheme="https://isaacguan.github.io/tags/convex-hull/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://isaacguan.github.io/2017/11/01/Hello-World/"/>
    <id>https://isaacguan.github.io/2017/11/01/Hello-World/</id>
    <published>2017-11-01T20:59:25.000Z</published>
    <updated>2017-11-02T03:12:48.160Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Existence precedes essence.</p></blockquote><p>During the high school years, I once kept a diary, sort of artsy lifestyle possessed by the petty bourgeoisie. And this experience told me the truth that writing is really time consuming, especially when you are making ‘sentimental twaddle’ on trivial things in daily life.</p><p>Time flies. I haven’t been keeping that habit for a long time and I will be 23 this month. As every young man in his 20s, I feel at a loss from time to time. Looking back on the past few years, seemingly I have gone through a lot of things and met up with a lot of people, but future still remains uncertain.</p><p>Some people of this era are distressed and tend to explore the meaning of their existence. That is why I am quoting the words of <a href="https://en.wikipedia.org/wiki/Jean-Paul_Sartre" target="_blank" rel="external">Jean-Paul Sartre</a> at the beginning of this post. It tells that life could be meaningless according to my understanding, unless you create yourself a meaning.</p><p>But I cannot say that I am an existentialist. Existentialist should be fearless, like <a href="https://en.wikipedia.org/wiki/Friedrich_Nietzsche" target="_blank" rel="external">Nietzsche</a>, who asserted that ‘God is dead’. I am just following the guidance of these great philosophers to add something that I believe is meaningful to my life.</p><p>Thus, I decided to build this place and record something of myself, which generally includes:</p><ul><li>Something about my study (algorithms, programming, projects I am doing, etc.)</li><li>Something about my hobby (traveling, cycling, reading, photographing, etc.)</li><li>And more possibilities…</li></ul><p>It is lucky for me to live in this digital age, such that I can easily build up this small website on my own using <a href="https://pages.github.com/" target="_blank" rel="external">Github Pages</a> as blogging platform and <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a> as framework. I also would like to express my thanks to <a href="https://github.com/fi3ework" target="_blank" rel="external">fi3ework</a> who designed this beautiful theme <a href="https://github.com/fi3ework/hexo-theme-archer" target="_blank" rel="external">archer</a> that I am using.</p><p>Anyhow, this is the very first post of my blog. Wish myself happy blogging :)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;Existence precedes essence.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;During the high school years, I once kept a diary, sort of artsy lifestyle 
      
    
    </summary>
    
    
      <category term="hello world" scheme="https://isaacguan.github.io/tags/hello-world/"/>
    
  </entry>
  
</feed>
